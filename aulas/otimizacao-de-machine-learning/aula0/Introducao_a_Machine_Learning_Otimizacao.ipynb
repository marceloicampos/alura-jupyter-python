{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Entendendo o que é um parâmetro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "y7ik04NlDZMA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "uri = \"../../otimizacao-de-machine-learning/base-data/machine-learning-carros-simulacao.csv\"\n",
        "dados = pd.read_csv(uri).drop(columns=[\"Unnamed: 0\"], axis=1)\n",
        "dados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "b52E4e1hjegN",
        "outputId": "97420810-da24-4bd7-8b8d-242c06aa220a"
      },
      "outputs": [],
      "source": [
        "# situação horrível de \"azar\" onde as classes estão ordenadas por padrão\n",
        "\n",
        "dados_azar = dados.sort_values(\"vendido\", ascending=True)\n",
        "x_azar = dados_azar[[\"preco\", \"idade_do_modelo\",\"km_por_ano\"]]\n",
        "y_azar = dados_azar[\"vendido\"]\n",
        "dados_azar.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZNT26vFEeYmz"
      },
      "outputs": [],
      "source": [
        "# gerando um modelo DummyClassifier\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DummyClassifier()\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com dummy stratified, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "73mCcFA_eG_K"
      },
      "outputs": [],
      "source": [
        "# gerando um modelo DecisionTreeClassifier com máxima profundidade de 2\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = 10, return_train_score=False)\n",
        "media = results['test_score'].mean()\n",
        "desvio_padrao = results['test_score'].std()\n",
        "print(\"Accuracy com cross validation, 10 = [%.2f, %.2f]\" % ((media - 2 * desvio_padrao)*100, (media + 2 * desvio_padrao) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5C8Y6J-PGpYf"
      },
      "outputs": [],
      "source": [
        "# gerando dados elatorios de modelo de carro para simulacao de agrupamento ao usar nosso estimador. a nova coluna modelo será uma variável categórica, não uma ordem nessa variável modelo\n",
        "\n",
        "np.random.seed(SEED)\n",
        "dados['modelo'] = dados.idade_do_modelo + np.random.randint(-2, 3, size=10000)\n",
        "dados.modelo = dados.modelo + abs(dados.modelo.min()) + 1\n",
        "dados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "3hmjt7qPHOZY"
      },
      "outputs": [],
      "source": [
        "# função para imprimir os resultados\n",
        "\n",
        "def imprime_resultados(results):\n",
        "  media = results['test_score'].mean() * 100\n",
        "  desvio = results['test_score'].std() * 100\n",
        "  print(\"Accuracy médio %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GroupKFold para analisar como o modelo se comporta com novos grupos\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "goijy0rSS7n-"
      },
      "outputs": [],
      "source": [
        "# GroupKFold em um pipeline com StandardScaler e SVC\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "modelo = SVC()\n",
        "\n",
        "pipeline = Pipeline([('transformacao',scaler), ('estimador',modelo)])\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "results = cross_validate(pipeline, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ESCOLHEMOS O DecisionTreeClassifier para o caso específico de classificação com o GroupKFold para analisar como o modelo se comporta com novos grupos\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=2)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "modelo.fit(x_azar, y_azar)\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
        "                class_names=[\"não\", \"sim\"], \n",
        "                feature_names =  features)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Outros Atributos para o DecisionTreeClassifier\n",
        "\n",
        "# DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
        "#             max_features=None, max_leaf_nodes=None,\n",
        "#             min_impurity_decrease=0.0, min_impurity_split=None,\n",
        "#             min_samples_leaf=1, min_samples_split=2,\n",
        "#             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
        "#             splitter='best')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ESCOLHEMOS O DecisionTreeClassifier para o caso específico de classificação com o GroupKFold para analisar como o modelo se comporta com novos grupos\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=3)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "modelo.fit(x_azar, y_azar)\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(modelo, out_file=None, filled=True, rounded=True, \n",
        "                class_names=[\"não\", \"sim\"], \n",
        "                feature_names =  features)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GroupKFold para analisar como o modelo se comporta com novos grupos. Com profundidade 10 a acurácia fica pior\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "SEED = 301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "cv = GroupKFold(n_splits = 10)\n",
        "modelo = DecisionTreeClassifier(max_depth=10)\n",
        "results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "imprime_resultados(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Quanto mais complexa a árvore, melhor ? Testando parâmetros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "\n",
        "# --- código original com max_depth = 3\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=False)\n",
        "# --- código original\n",
        "\n",
        "  print(\"Árvore max_depth = %d, media =%.2f\" % (max_depth, results['test_score'].mean() * 100))\n",
        "\n",
        "for i in range (1, 33):\n",
        "      roda_arvore_de_decisao(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3. Otimizando um hiper parâmetro e o problema do overfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth):\n",
        "\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "\n",
        "  print(\"Arvore max_depth = %d, treino = %.2f, teste = %.2f,\" % (max_depth, results['train_score'].mean() * 100, results['test_score'].mean() * 100))\n",
        "\n",
        "  tabela = [max_depth, train_score, test_score]\n",
        "\n",
        "  return tabela\n",
        "\n",
        "resultados = [roda_arvore_de_decisao(i) for i in range (1, 33)]\n",
        "resultados = pd.DataFrame(resultados, columns=['max_depth', 'train_score', 'test_score'])\n",
        "\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.lineplot(x = \"max_depth\", y = \"train_score\", data = resultados)\n",
        "sns.lineplot(x = \"max_depth\", y = \"test_score\", data = resultados)\n",
        "plt.legend([\"Treino\", \"Teste\"])\n",
        "# aconteceu um over fit no treino e cada vez pior nos testes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados.sort_values(\"test_score\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Explorando hiper parâmetros de duas dimensões"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "\n",
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf)\n",
        "  # acima estão os hiper parâmetros\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "  print(\"Arvore max_depth = %d, min_samples_leaf = %d, treino = %.2f, teste = %.2f\" % (max_depth, min_samples_leaf, train_score, test_score))\n",
        "  tabela = [max_depth, min_samples_leaf, train_score, test_score]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    # for min_samples_leaf in range(1,33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "      resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Matriz de correlação e explorando mais e mais espaços de parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.heatmap(corr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.plotting.scatter_matrix(resultados, figsize = (14, 8), alpha = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.pairplot(resultados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    # for min_samples_leaf in [32, 64, 128, 256]:\n",
        "    for min_samples_leaf in [128, 192, 256, 512]:\n",
        "      tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf)\n",
        "      resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"train\",\"test\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.set(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3 Explorando 3 dimensões de hiper parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split):\n",
        "  SEED = 301\n",
        "  np.random.seed(SEED)\n",
        "\n",
        "  cv = GroupKFold(n_splits = 10)\n",
        "  modelo = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf = min_samples_leaf, min_samples_split = min_samples_split)\n",
        "  results = cross_validate(modelo, x_azar, y_azar, cv = cv, groups = dados.modelo, return_train_score=True)\n",
        "  fit_time = results['fit_time'].mean()\n",
        "  score_time = results['score_time'].mean()\n",
        "  train_score = results['train_score'].mean() * 100\n",
        "  test_score = results['test_score'].mean() * 100\n",
        "  tabela = [max_depth, min_samples_leaf, min_samples_split, train_score, test_score, fit_time, score_time]\n",
        "  return tabela\n",
        "\n",
        "def busca():\n",
        "  resultados = []\n",
        "  for max_depth in range(1,33):\n",
        "    for min_samples_leaf in [32, 64, 128, 256]:\n",
        "      for min_samples_split in [32, 64, 128, 256]:\n",
        "        tabela = roda_arvore_de_decisao(max_depth, min_samples_leaf, min_samples_split)\n",
        "        resultados.append(tabela)\n",
        "  resultados = pd.DataFrame(resultados, columns= [\"max_depth\",\"min_samples_leaf\",\"min_samples_split\",\"train\",\"test\", \"fit_time\", \"score_time\"])\n",
        "  return resultados\n",
        "\n",
        "resultados = busca()\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = resultados.corr()\n",
        "corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set(style=\"white\")\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resultados.sort_values(\"test\", ascending=False).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4 Explorando espaço de hiper parâmetros com GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\" : [32, 64, 128],\n",
        "    \"min_samples_leaf\" : [32, 64, 128],\n",
        "    \"criterion\" : [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = GroupKFold(n_splits = 10))\n",
        "busca.fit(x_azar, y_azar, groups = dados.modelo)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(busca.best_params_)\n",
        "print(busca.best_score_ * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "melhor = busca.best_estimator_\n",
        "melhor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "predicoes = melhor.predict(x_azar)\n",
        "accuracy = accuracy_score(predicoes, y_azar) * 100\n",
        "print(\"Accuracy para os dados foi %.2f%%\" % accuracy)\n",
        "\n",
        "# evitamos essa abordagem, pois estamos sendo otimistas demais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Nested cross validation e validando o melhor modelo\n",
        "##### - Realizamos abaixo uma estimativa sem ocorrer o vício nos dados\n",
        "##### - No caso de cross validation com busca de hiper parâmetros, fazemos uma nova validação cruzada (ou nested  cross validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Infelizmente o PANDAS não suporta nested cross validation com GROUP K Fold para prever resultados.Então NÃO EXECUTAR !\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = GroupKFold(n_splits=10), groups = dados.modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Então usaremos o KFold normal\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "SEED=301\n",
        "np.random.seed(SEED)\n",
        "\n",
        "espaco_de_parametros = {\n",
        "    \"max_depth\" : [3, 5],\n",
        "    \"min_samples_split\": [32, 64, 128],\n",
        "    \"min_samples_leaf\": [32, 64, 128],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "busca = GridSearchCV(DecisionTreeClassifier(),\n",
        "                    espaco_de_parametros,\n",
        "                    cv = KFold(n_splits = 5, shuffle=True))\n",
        "\n",
        "busca.fit(x_azar, y_azar)\n",
        "resultados = pd.DataFrame(busca.cv_results_)\n",
        "resultados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(busca, x_azar, y_azar, cv = KFold(n_splits=5, shuffle=True))\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imprime_score(scores):\n",
        "  media = scores.mean() * 100\n",
        "  desvio = scores.std() * 100\n",
        "  print(\"Accuracy médio %.2f\" % media)\n",
        "  print(\"Intervalo [%.2f, %.2f]\" % (media - 2 * desvio, media + 2 * desvio))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imprime_score(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "melhor = busca.best_estimator_\n",
        "melhor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "\n",
        "features = x_azar.columns\n",
        "dot_data = export_graphviz(melhor, out_file=None, filled=True, rounded=True,\n",
        "                          class_names=[\"não\",\"sim\"],\n",
        "                          feature_names=features)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Introdução_a_Machine_Learning_Otimização.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
